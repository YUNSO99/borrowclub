{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'대출일시'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3806\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '대출일시'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m loan_info_df \u001b[39m=\u001b[39m loan_info_df\u001b[39m.\u001b[39mloc[:, \u001b[39m~\u001b[39mloan_info_df\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39mcontains(\u001b[39m'\u001b[39m\u001b[39m^Unnamed\u001b[39m\u001b[39m'\u001b[39m)]\n\u001b[1;32m     17\u001b[0m \u001b[39m# 대출 정보 전처리: 대출일자 추출\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m loan_info_df[\u001b[39m'\u001b[39m\u001b[39m대출일자\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_datetime(loan_info_df[\u001b[39m'\u001b[39m\u001b[39m대출일시\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     20\u001b[0m \u001b[39m# 대출 요약 정보 생성: 마지막 대출일자와 총 대출 수\u001b[39;00m\n\u001b[1;32m     21\u001b[0m loan_summary \u001b[39m=\u001b[39m loan_info_df\u001b[39m.\u001b[39mgroupby(\u001b[39m'\u001b[39m\u001b[39m도서ID\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39magg(\n\u001b[1;32m     22\u001b[0m     마지막대출일자\u001b[39m=\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m대출일자\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmax\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[1;32m     23\u001b[0m     총대출수\u001b[39m=\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m대출일자\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcount\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     24\u001b[0m )\u001b[39m.\u001b[39mreset_index()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mget_loc(key)\n\u001b[1;32m   4103\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(casted_key, \u001b[39mslice\u001b[39m) \u001b[39mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[39misinstance\u001b[39m(casted_key, abc\u001b[39m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mslice\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: '대출일시'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 파일 경로 설정\n",
    "book_info_path = r'단행본(도서)정보.csv'\n",
    "loan_info_path = r'대출정보.csv'\n",
    "\n",
    "\n",
    "# 파일 읽기 (euc-kr 인코딩)\n",
    "book_info_df = pd.read_csv(book_info_path, encoding='euc-kr')\n",
    "loan_info_df = pd.read_csv(loan_info_path, encoding='euc-kr')\n",
    "\n",
    "# Unnamed 열 제거\n",
    "book_info_df = book_info_df.loc[:, ~book_info_df.columns.str.contains('^Unnamed')]\n",
    "loan_info_df = loan_info_df.loc[:, ~loan_info_df.columns.str.contains('^Unnamed')]\n",
    "\n",
    "# 대출 정보 전처리: 대출일자 추출\n",
    "loan_info_df['대출일자'] = pd.to_datetime(loan_info_df['대출일시'])\n",
    "\n",
    "# 대출 요약 정보 생성: 마지막 대출일자와 총 대출 수\n",
    "loan_summary = loan_info_df.groupby('도서ID').agg(\n",
    "    마지막대출일자=('대출일자', 'max'),\n",
    "    총대출수=('대출일자', 'count')\n",
    ").reset_index()\n",
    "\n",
    "# 단행본 정보와 대출 요약 정보 병합 (단행본 정보 모든 열 유지)\n",
    "merged_info = pd.merge(book_info_df, loan_summary, on='도서ID', how='left')\n",
    "\n",
    "# 대출 기록이 없는 도서 처리\n",
    "merged_info['마지막대출일자'] = merged_info['마지막대출일자'].fillna('대출 기록 없음')\n",
    "merged_info['총대출수'] = merged_info['총대출수'].fillna(0).astype(int)\n",
    "\n",
    "# 결과를 CSV 파일로 저장\n",
    "output_path = r'통합_정보.csv'\n",
    "merged_info.to_csv(output_path, index=False, encoding='euc-kr')\n",
    "\n",
    "# 결과 미리 보기\n",
    "merged_info.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "보존서고에 있는 책: 138697권\n",
      "4층인문에 있는 책: 162454권\n"
     ]
    }
   ],
   "source": [
    "# 통합_정보.csv 파일 로드\n",
    "output_path = r'통합_정보.csv'\n",
    "merged_info = pd.read_csv(output_path, encoding='euc-kr')\n",
    "\n",
    "# 소장위치별 도서 수 계산\n",
    "location_counts = merged_info['소장위치'].value_counts()\n",
    "\n",
    "# 보존서고와 4층인문의 책 수 확인\n",
    "preserved_books = location_counts.get('보존서고', 0)\n",
    "fourth_floor_books = location_counts.get('4층인문', 0)\n",
    "\n",
    "print(f\"보존서고에 있는 책: {preserved_books}권\")\n",
    "print(f\"4층인문에 있는 책: {fourth_floor_books}권\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2g/9_1xks7j21j8_vjr52g7g8hr0000gn/T/ipykernel_39122/2300858549.py:5: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  fourth_floor_books['마지막대출일자'] = pd.to_datetime(fourth_floor_books['마지막대출일자'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4층인문에 있는 책 중 가장 대출일자가 오래된 날짜: 2004-11-01\n",
      "해당 데이터의 행 번호: [202402]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2g/9_1xks7j21j8_vjr52g7g8hr0000gn/T/ipykernel_39122/2300858549.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fourth_floor_books['마지막대출일자'] = pd.to_datetime(fourth_floor_books['마지막대출일자'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "# '4층인문'에 있는 책 필터링\n",
    "fourth_floor_books = merged_info[merged_info['소장위치'] == '4층인문']\n",
    "\n",
    "# '마지막대출일자'가 '대출 기록 없음'이 아닌 경우만 고려\n",
    "fourth_floor_books['마지막대출일자'] = pd.to_datetime(fourth_floor_books['마지막대출일자'], errors='coerce')\n",
    "\n",
    "# 가장 오래된 대출 날짜와 해당 행 찾기\n",
    "oldest_loan_date = fourth_floor_books['마지막대출일자'].min()\n",
    "oldest_row = fourth_floor_books[fourth_floor_books['마지막대출일자'] == oldest_loan_date]\n",
    "\n",
    "# 행 번호 출력\n",
    "if oldest_row.empty or pd.isna(oldest_loan_date):\n",
    "    print(\"4층인문에 있는 책 중 대출 기록이 없습니다.\")\n",
    "else:\n",
    "    print(f\"4층인문에 있는 책 중 가장 대출일자가 오래된 날짜: {oldest_loan_date.date()}\")\n",
    "    print(f\"해당 데이터의 행 번호: {oldest_row.index.tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  서명                    저자  \\\n",
      "0  \"Das Recht kann nicht ungerecht sein …\" :Beitr...           Li, Wenchao   \n",
      "1  \"Der Zusammenhang der Dinge\" :Weltgleichnis un...       Gebhard, Walter   \n",
      "2  \"Ethik und Asthetik sind Eins\" :Beitrage zu Wi...  Lutterfelds, Wilhelm   \n",
      "3  \"God ordained this war\" :sermons on the sectio...  Chesebrough, David B   \n",
      "4                    \"Huis clos\" de Jean-Paul Sartre        Bishop, Thomas   \n",
      "\n",
      "                                  출판사  출판년도  총대출수     마지막대출일자  중복책권수  \\\n",
      "0                Franz Steiner Verlag  2015     1  2016-06-07      1   \n",
      "1                         M. Niemeyer  1984     0                  1   \n",
      "2                          Peter Lang  2007     1  2017-12-12      1   \n",
      "3  University of South Carolina Press  1991     0                  1   \n",
      "4                            Hachette  1979     2  2017-05-22      1   \n",
      "\n",
      "        분류코드  \n",
      "0        193  \n",
      "1        193  \n",
      "2  111.85092  \n",
      "3  252.00973  \n",
      "4        448  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# NA 값을 처리 (groupby를 위한 열에서 누락된 값 방지)\n",
    "merged_info[['서명', '출판사', '출판년도', '저자', '분류코드']] = merged_info[['서명', '출판사', '출판년도', '저자', '분류코드']].fillna('')\n",
    "\n",
    "# '마지막대출일자'를 datetime 형식으로 변환\n",
    "merged_info['마지막대출일자'] = pd.to_datetime(merged_info['마지막대출일자'], errors='coerce')\n",
    "\n",
    "# 중복된 책 정보를 합침 (분류코드를 첫 번째 값으로 유지)\n",
    "grouped_books = merged_info.groupby(['서명', '저자', '출판사', '출판년도']).agg(\n",
    "    총대출수=('총대출수', 'sum'),  # 총 대출 수 합산\n",
    "    마지막대출일자=('마지막대출일자', 'max'),  # 가장 최근 대출일자 선택\n",
    "    중복책권수=('서명', 'size'),  # 중복된 행 수\n",
    "    분류코드=('분류코드', 'first'),  # 첫 번째 분류코드 유지 (중복 없이)\n",
    "    도서ID=('도서ID', lambda x: ', '.join(x.astype(str)))  # 중복된 도서 ID를 문자열로 묶음\n",
    ").reset_index()\n",
    "\n",
    "# 마지막대출일자를 다시 문자열로 변환 (필요시)\n",
    "grouped_books['마지막대출일자'] = grouped_books['마지막대출일자'].dt.strftime('%Y-%m-%d').fillna('')\n",
    "\n",
    "# 연도를 숫자로만 바꾸는 함수 정의\n",
    "def clean_year(year):\n",
    "    match = re.search(r'\\d{4}', str(year))\n",
    "    return match.group(0) if match else year\n",
    "\n",
    "# 출판년도 컬럼 변환\n",
    "grouped_books[\"출판년도\"] = grouped_books[\"출판년도\"].apply(clean_year)\n",
    "\n",
    "# 결과 미리 보기\n",
    "print(grouped_books.head())\n",
    "\n",
    "# 결과 저장 (필요시)\n",
    "output_path = '통합_정보_합침.csv'\n",
    "grouped_books.to_csv(output_path, index=False, encoding='euc-kr')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'대출일시'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3806\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '대출일시'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m merged_info \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(merged_info_path, encoding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39meuc-kr\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[39m# 1. 대출일시에서 연도를 추출\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m loan_info[\u001b[39m'\u001b[39m\u001b[39m대출연도\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_datetime(loan_info[\u001b[39m'\u001b[39m\u001b[39m대출일시\u001b[39m\u001b[39m'\u001b[39m], errors\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcoerce\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mdt\u001b[39m.\u001b[39myear\n\u001b[1;32m     12\u001b[0m \u001b[39m# 2. 연대를 분류하는 함수 정의\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mclassify_decade\u001b[39m(year):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mget_loc(key)\n\u001b[1;32m   4103\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(casted_key, \u001b[39mslice\u001b[39m) \u001b[39mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[39misinstance\u001b[39m(casted_key, abc\u001b[39m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mslice\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: '대출일시'"
     ]
    }
   ],
   "source": [
    "# 파일 경로 설정\n",
    "loan_info_path = '대출정보.csv'  # 대출 정보 파일 경로\n",
    "merged_info_path = '통합_정보.csv'  # 통합 정보 파일 경로\n",
    "\n",
    "# 데이터 로드\n",
    "loan_info = pd.read_csv(loan_info_path, encoding='euc-kr')\n",
    "merged_info = pd.read_csv(merged_info_path, encoding='euc-kr')\n",
    "\n",
    "# 1. 대출일시에서 연도를 추출\n",
    "loan_info['대출연도'] = pd.to_datetime(loan_info['대출일시'], errors='coerce').dt.year\n",
    "\n",
    "# 2. 연대를 분류하는 함수 정의\n",
    "def classify_decade(year):\n",
    "    if pd.isna(year):\n",
    "        return 'Unknown'\n",
    "    elif 2000 <= year < 2010:\n",
    "        return '2000s'\n",
    "    elif 2010 <= year < 2020:\n",
    "        return '2010s'\n",
    "    elif 2020 <= year < 2030:\n",
    "        return '2020s'\n",
    "    else:\n",
    "        return 'Others'\n",
    "\n",
    "# 연대 정보 추가\n",
    "loan_info['연대'] = loan_info['대출연도'].apply(classify_decade)\n",
    "\n",
    "# 3. 십진분류 생성: 첫 두 자리 + 0 생성\n",
    "def generate_decimal_classification(code):\n",
    "    try:\n",
    "        code = str(code).zfill(3)  # 항상 세 자리로 보정\n",
    "        decimal_code = code[:2] + '0'  # 첫 두 자리 추출 후 마지막에 0 추가\n",
    "        return decimal_code\n",
    "    except:\n",
    "        return ''\n",
    "\n",
    "# 원본 '분류코드'와 '십진분류' 추가\n",
    "merged_info['십진분류'] = merged_info['분류코드'].apply(generate_decimal_classification)\n",
    "\n",
    "# 4. 통합 정보에서 중복된 책 정보를 통합\n",
    "merged_info[['서명', '출판사', '출판년도', '저자', '분류코드', '십진분류']] = merged_info[['서명', '출판사', '출판년도', '저자', '분류코드', '십진분류']].fillna('')\n",
    "grouped_books = merged_info.groupby(['서명', '저자', '출판사', '출판년도', '분류코드', '십진분류']).agg(\n",
    "    총대출수=('총대출수', 'sum'),\n",
    "    마지막대출일자=('마지막대출일자', 'max'),\n",
    "    중복책권수=('서명', 'size')\n",
    ").reset_index()\n",
    "\n",
    "# 5. 대출 정보와 통합 정보 병합\n",
    "loan_info_with_titles = pd.merge(loan_info, merged_info[['서명', '도서ID']], on='도서ID', how='left')\n",
    "\n",
    "# 6. 서명과 연대별 대출 횟수 집계\n",
    "decade_loans = loan_info_with_titles.groupby(['서명', '연대']).size().reset_index(name='연대별대출횟수')\n",
    "\n",
    "# 7. 연대별 대출 횟수를 피벗 형태로 변환\n",
    "pivot_loans = decade_loans.pivot(index='서명', columns='연대', values='연대별대출횟수').fillna(0)\n",
    "pivot_loans = pivot_loans.reset_index()\n",
    "\n",
    "# 8. 통합 정보와 연대별 대출 횟수 병합\n",
    "final_data = pd.merge(grouped_books, pivot_loans, on='서명', how='left')\n",
    "\n",
    "# 9. NA 값 처리\n",
    "final_data = final_data.fillna(0)\n",
    "\n",
    "# 결과를 CSV 파일로 저장\n",
    "final_data.to_csv('통합_정보_연대별_대출횟수.csv', index=False, encoding='euc-kr')\n",
    "\n",
    "# 결과 확인\n",
    "print(final_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '통합_정보_연대별_대출횟수.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# CSV 파일 로드\u001b[39;00m\n\u001b[1;32m      2\u001b[0m file_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m통합_정보_연대별_대출횟수.csv\u001b[39m\u001b[39m'\u001b[39m  \u001b[39m# 파일 경로\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(file_path, encoding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39meuc-kr\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[39m# 연대별 대출 데이터 컬럼 추출 (2000s, 2010s, 2020s)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m decade_columns \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39m2000s\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m2010s\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m2020s\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m    622\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_engine(f, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1881\u001b[0m     f,\n\u001b[1;32m   1882\u001b[0m     mode,\n\u001b[1;32m   1883\u001b[0m     encoding\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m),\n\u001b[1;32m   1884\u001b[0m     compression\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mcompression\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m),\n\u001b[1;32m   1885\u001b[0m     memory_map\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mmemory_map\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m),\n\u001b[1;32m   1886\u001b[0m     is_text\u001b[39m=\u001b[39mis_text,\n\u001b[1;32m   1887\u001b[0m     errors\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mencoding_errors\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mstrict\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1888\u001b[0m     storage_options\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mstorage_options\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m),\n\u001b[1;32m   1889\u001b[0m )\n\u001b[1;32m   1890\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[39m.\u001b[39mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[39m=\u001b[39mioargs\u001b[39m.\u001b[39mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[39m=\u001b[39merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '통합_정보_연대별_대출횟수.csv'"
     ]
    }
   ],
   "source": [
    "# CSV 파일 로드\n",
    "file_path = '통합_정보_연대별_대출횟수.csv'  # 파일 경로\n",
    "data = pd.read_csv(file_path, encoding='euc-kr')\n",
    "\n",
    "# 연대별 대출 데이터 컬럼 추출 (2000s, 2010s, 2020s)\n",
    "decade_columns = ['2000s', '2010s', '2020s']\n",
    "\n",
    "# '십진분류' 데이터를 정수형 문자열로 통일\n",
    "data['십진분류'] = data['십진분류'].apply(lambda x: str(x).split('.')[0].zfill(3))\n",
    "\n",
    "# 결과 저장용 리스트\n",
    "top_5_by_decade = []\n",
    "\n",
    "# 각 연대별로 처리\n",
    "for decade in decade_columns:\n",
    "    temp = data[['십진분류', decade]].copy()  # 십진분류와 해당 연대 대출 데이터만 추출\n",
    "    temp = temp[temp[decade] > 0]  # 대출 횟수가 0보다 큰 경우만 필터링\n",
    "    temp = temp.groupby('십진분류')[decade].sum().reset_index()  # 십진분류별 대출 합계\n",
    "    temp = temp.sort_values(by=decade, ascending=False).head(5)  # 대출 횟수 기준 상위 5개 추출\n",
    "    temp['연대'] = decade  # 연대 정보 추가\n",
    "    top_5_by_decade.append(temp)\n",
    "\n",
    "# 결과 출력\n",
    "for result in top_5_by_decade:\n",
    "    decade = result['연대'].iloc[0]\n",
    "    print(f\"\\n--- {decade} 상위 5개 십진분류 ---\")\n",
    "    print(result[['십진분류', decade]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\songbh0304\\AppData\\Local\\Temp\\ipykernel_21552\\244434297.py:5: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(file_path, encoding='euc-kr')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 연대별 대출 수 증가율 상위 20개 십진분류 ---\n",
      "   십진분류       증가율    2000s    2020s\n",
      "0   450  4.333333      3.0     16.0\n",
      "1   480  2.629630     27.0     98.0\n",
      "2   002  1.285714      7.0     16.0\n",
      "3   510  1.200000      5.0     11.0\n",
      "4   060  1.054054     74.0    152.0\n",
      "5   470  0.975000     40.0     79.0\n",
      "6   690  0.937500     32.0     62.0\n",
      "7   001  0.866720   1253.0   2339.0\n",
      "8   490  0.575419    179.0    282.0\n",
      "9   220  0.518976  11831.0  17971.0\n",
      "10  460  0.354839    155.0    210.0\n",
      "11  000  0.314607   1157.0   1521.0\n",
      "12  730  0.194313    211.0    252.0\n",
      "13  110  0.099061   2342.0   2574.0\n",
      "14  120  0.076806   2630.0   2832.0\n",
      "15  340  0.000000      6.0      6.0\n",
      "16  740 -0.026680   6222.0   6056.0\n",
      "17  140 -0.160241   1660.0   1394.0\n",
      "18  410 -0.245057  13503.0  10194.0\n",
      "19  190 -0.278657  13967.0  10075.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 파일 로드\n",
    "file_path = '통합_정보_연대별_대출횟수.csv'  # 파일 경로\n",
    "data = pd.read_csv(file_path, encoding='euc-kr')\n",
    "\n",
    "# 연대별 대출 데이터 컬럼 추출 (2000s, 2010s, 2020s)\n",
    "decade_columns = ['2000s', '2010s', '2020s']\n",
    "\n",
    "# '십진분류' 데이터를 정수형 문자열로 통일\n",
    "data['십진분류'] = data['십진분류'].apply(lambda x: str(x).split('.')[0].zfill(3))\n",
    "\n",
    "# 십진분류별로 대출 데이터를 합산\n",
    "grouped_data = data.groupby('십진분류')[decade_columns].sum().reset_index()\n",
    "\n",
    "# 대출 수 증가율 계산 (2000s 대출 수가 0인 경우 제외)\n",
    "grouped_data = grouped_data[grouped_data['2000s'] > 0]  # 2000s 대출 수가 0인 행 제거\n",
    "grouped_data['증가율'] = (grouped_data['2020s'] - grouped_data['2000s']) / grouped_data['2000s']\n",
    "\n",
    "# 증가율 기준으로 상위 20개 추출\n",
    "result = grouped_data.sort_values(by='증가율', ascending=False).head(20).reset_index(drop=True)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"\\n--- 연대별 대출 수 증가율 상위 20개 십진분류 ---\")\n",
    "print(result[['십진분류', '증가율', '2000s', '2020s']])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 450\t4.333333\t3.0\t16.0\t이탈리아, 루마니아어\n",
    "2 480\t2.629630\t27.0\t98.0\t고대, 현대 그리스어\n",
    "3 002\t1.285714\t7.0\t16.0\t총류 (컴퓨터 과학, 지식, 시스템)\n",
    "4 510\t1.200000\t5.0\t11.0\t수학\n",
    "5 060\t1.054054\t74.0\t152.0\t협회, 박물관학\n",
    "6 470\t0.975000\t40.0\t79.0\t라틴과 이탤릭 언어\n",
    "7 690\t0.937500\t32.0\t62.0\t건축\n",
    "8 001\t0.866720\t1253.0\t2339.0\t컴퓨터 과학, 정보 총류\n",
    "9 490\t0.575419\t179.0\t282.0\t다른 기타 언어\n",
    "10 220\t0.518976\t11831.0\t17971.0\t성서\n",
    "11 460\t0.354839\t155.0\t210.0\t스페인, 포르투갈어\n",
    "12 000\t0.314607\t1157.0\t1521.0\t컴퓨터 과학, 정보 총류\n",
    "13 730\t0.194313\t211.0\t252.0\t조각품, 도예와 금속제품\n",
    "14 110\t0.099061\t2342.0\t2574.0\t형이상학\n",
    "15 120\t0.076806\t2630.0\t2832.0\t인식론\n",
    "16 340\t0.000000\t6.0\t6.0\t법학\n",
    "17 740\t-0.026680\t6222.0\t6056.0\t인쇄예술\n",
    "18 140\t-0.160241\t1660.0\t1394.0\t철학파\n",
    "19 410\t-0.245057\t13503.0\t10194.0\t언어학\n",
    "20 190\t-0.278657\t13967.0\t10075.0\t현대 서양철학\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '통합_정보_연대별_대출횟수.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39m# CSV 파일 로드\u001b[39;00m\n\u001b[1;32m      4\u001b[0m file_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m통합_정보_연대별_대출횟수.csv\u001b[39m\u001b[39m'\u001b[39m  \u001b[39m# 파일 경로\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(file_path, encoding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39meuc-kr\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[39m# 연대별 대출 데이터 컬럼 추출 (2000s, 2010s, 2020s)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m decade_columns \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39m2000s\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m2010s\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m2020s\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m    622\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_engine(f, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1881\u001b[0m     f,\n\u001b[1;32m   1882\u001b[0m     mode,\n\u001b[1;32m   1883\u001b[0m     encoding\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m),\n\u001b[1;32m   1884\u001b[0m     compression\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mcompression\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m),\n\u001b[1;32m   1885\u001b[0m     memory_map\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mmemory_map\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m),\n\u001b[1;32m   1886\u001b[0m     is_text\u001b[39m=\u001b[39mis_text,\n\u001b[1;32m   1887\u001b[0m     errors\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mencoding_errors\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mstrict\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1888\u001b[0m     storage_options\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mstorage_options\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m),\n\u001b[1;32m   1889\u001b[0m )\n\u001b[1;32m   1890\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[39m.\u001b[39mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[39m=\u001b[39mioargs\u001b[39m.\u001b[39mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[39m=\u001b[39merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '통합_정보_연대별_대출횟수.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 파일 로드\n",
    "file_path = '통합_정보_연대별_대출횟수.csv'  # 파일 경로\n",
    "data = pd.read_csv(file_path, encoding='euc-kr')\n",
    "\n",
    "# 연대별 대출 데이터 컬럼 추출 (2000s, 2010s, 2020s)\n",
    "decade_columns = ['2000s', '2010s', '2020s']\n",
    "\n",
    "# '십진분류' 데이터를 정수형 문자열로 통일\n",
    "data['십진분류'] = data['십진분류'].apply(lambda x: str(x).split('.')[0].zfill(3))\n",
    "\n",
    "# 십진분류별로 대출 데이터를 합산\n",
    "grouped_data = data.groupby('십진분류')[decade_columns].sum().reset_index()\n",
    "\n",
    "# 대출 수 증가율 계산 (2000s 대출 수가 0인 경우 제외)\n",
    "grouped_data = grouped_data[grouped_data['2000s'] > 0]  # 2000s 대출 수가 0인 행 제거\n",
    "grouped_data['증가율'] = (grouped_data['2020s'] - grouped_data['2000s']) / grouped_data['2000s']\n",
    "\n",
    "# 증가율 기준으로 하위 20개 추출\n",
    "result = grouped_data.sort_values(by='증가율', ascending=True).head(20).reset_index(drop=True)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"\\n--- 연대별 대출 수 증가율 하위 20개 십진분류 ---\")\n",
    "print(result[['십진분류', '증가율', '2000s', '2020s']])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하위 20순위\n",
    "1\t360\t-1.000000\t5.0\t0.0\t사회서비스\n",
    "2\t030\t-0.996212\t528.0\t2.0\t백과사전\n",
    "3\t710\t-0.945122\t164.0\t9.0\t도시계획, 조경술\n",
    "4\t070\t-0.939394\t66.0\t4.0\t뉴스 매체, 저널리즘, 출판\n",
    "5\t320\t-0.934211\t76.0\t5.0\t정치학\n",
    "6\t600\t-0.923077\t13.0\t1.0\t기술\n",
    "7\t500\t-0.888889\t9.0\t1.0\t과학\n",
    "8\t760\t-0.854167\t96.0\t14.0\t제작술\n",
    "9\t990\t-0.835294\t85.0\t14.0\t기타지역 역사\n",
    "10\t970\t-0.814758\t1965.0\t364.0\t북아메리카 역사\n",
    "11\t080\t-0.808751\t2651.0\t507.0\t일반전집\n",
    "12\t810\t-0.794926\t473.0\t97.0\t미국문학\n",
    "13\t920\t-0.791874\t2412.0\t502.0\t전기와 계보학\n",
    "14\t910\t-0.786158\t32711.0\t6995.0\t지리와 여행\n",
    "15\t950\t-0.759036\t47451.0\t11434.0\t아시아 역사\n",
    "16\t980\t-0.746269\t201.0\t51.0\t남아메리카 역사\n",
    "17\t770\t-0.742306\t3217.0\t829.0\t사진술\n",
    "18\t620\t-0.730769\t26.0\t7.0\t공학\n",
    "19\t390\t-0.729596\t5673.0\t1534.0\t관습, 에티켓과 민속전통\n",
    "20\t440\t-0.726134\t1676.0\t459.0\t프랑스 관련언어"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이렇게 대출이 증가한 것은 세계 나라의 언어, 컴퓨터과학, 성서, 철학 등이 있으며, 대출이 감소한 것은 각 세계의 역사, 도시계획, 사진술 등이 있다.\n",
    "이러한 트렌드를 통해 보존서고 이동 순위를 나타낼 수 있다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2024ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
